{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from helpers.utils import get_metrics, set_matplotlib_params\n",
    "from networks.nonlinearnet_aihuman import optimize_alpha, test_time_prediction\n",
    "\n",
    "set_matplotlib_params()\n",
    "warnings.filterwarnings('ignore')\n",
    "seed = 12\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(seed)\n",
    "rng = np.random.default_rng(seed) \n",
    "torch.set_default_dtype(torch.double)\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/filslechat/Documents/postdoc/reinvent_humanAI_reward/drd2_example.ipynb Cellule 3\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/filslechat/Documents/postdoc/reinvent_humanAI_reward/drd2_example.ipynb#Z1003sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m algo\u001b[39m.\u001b[39mfit(X_train_all)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/filslechat/Documents/postdoc/reinvent_humanAI_reward/drd2_example.ipynb#Z1003sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m c1_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(algo\u001b[39m.\u001b[39mlabels_)[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/filslechat/Documents/postdoc/reinvent_humanAI_reward/drd2_example.ipynb#Z1003sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m c2_train \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_train_all)) \u001b[39mif\u001b[39;00m i \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m c1]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/filslechat/Documents/postdoc/reinvent_humanAI_reward/drd2_example.ipynb#Z1003sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m X_train \u001b[39m=\u001b[39m X_train_all[c1_train, :]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/filslechat/Documents/postdoc/reinvent_humanAI_reward/drd2_example.ipynb#Z1003sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m X_train_h \u001b[39m=\u001b[39m X_train_all[c2_train,:]\n",
      "\u001b[1;32m/Users/filslechat/Documents/postdoc/reinvent_humanAI_reward/drd2_example.ipynb Cellule 3\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/filslechat/Documents/postdoc/reinvent_humanAI_reward/drd2_example.ipynb#Z1003sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m algo\u001b[39m.\u001b[39mfit(X_train_all)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/filslechat/Documents/postdoc/reinvent_humanAI_reward/drd2_example.ipynb#Z1003sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m c1_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(algo\u001b[39m.\u001b[39mlabels_)[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/filslechat/Documents/postdoc/reinvent_humanAI_reward/drd2_example.ipynb#Z1003sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m c2_train \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_train_all)) \u001b[39mif\u001b[39;00m i \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m c1]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/filslechat/Documents/postdoc/reinvent_humanAI_reward/drd2_example.ipynb#Z1003sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m X_train \u001b[39m=\u001b[39m X_train_all[c1_train, :]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/filslechat/Documents/postdoc/reinvent_humanAI_reward/drd2_example.ipynb#Z1003sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m X_train_h \u001b[39m=\u001b[39m X_train_all[c2_train,:]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'c1' is not defined"
     ]
    }
   ],
   "source": [
    "### From the undersampled training set, create two training sets: one for clf, one for human, based on K-means (K=2)\n",
    "\n",
    "drd2_train_undersampled = pd.read_csv(\"datasets/drd2_train_undersampled_ECFP_counts.csv\")\n",
    "d = 2048\n",
    "\n",
    "X_train_all = torch.tensor(drd2_train_undersampled[[f\"bit{i}\" for i in range(d)]].values, dtype=torch.double)\n",
    "y_train_all = torch.tensor(drd2_train_undersampled.activity.values, dtype=torch.double)\n",
    "\n",
    "algo = KMeans(n_clusters=2, random_state=seed, n_init=20, max_iter=5000, init=\"k-means++\")\n",
    "algo.fit(X_train_all)\n",
    "c1_train = np.where(algo.labels_)[0]\n",
    "c2_train = [i for i in range(len(X_train_all)) if i not in c1_train]\n",
    "\n",
    "X_train = X_train_all[c1_train, :]\n",
    "X_train_h = X_train_all[c2_train,:]\n",
    "\n",
    "y_train = y_train_all[c1_train].unsqueeze(1)\n",
    "y_train_h = y_train_all[c2_train].unsqueeze(1)\n",
    "\n",
    "### Test set\n",
    "\n",
    "drd2_test = pd.read_csv(\"datasets/drd2_test_ECFP_counts.csv\")\n",
    "X_test_all = torch.tensor(drd2_test[[f\"bit{i}\" for i in range(d)]].values, dtype=torch.double)\n",
    "y_test_all = torch.tensor(drd2_test.activity.values, dtype=torch.double)\n",
    "\n",
    "### Validation set as a fraction of the test set\n",
    "\n",
    "frac = .25\n",
    "ntest = len(X_test_all)\n",
    "nval = int(ntest * frac)\n",
    "idx = rng.choice(range(ntest), nval, replace=False)\n",
    "X_val = X_test_all[idx]\n",
    "y_val = y_test_all[idx].unsqueeze(1)\n",
    "\n",
    "notidx = [i for i in range(ntest) if i not in idx]\n",
    "X_test_all = X_test_all[notidx]\n",
    "y_test_all = y_test_all[notidx].unsqueeze(1)\n",
    "\n",
    "print(f\"Clf train set size: {len(X_train)}\")\n",
    "print(f\"Human train set size: {len(X_train_h)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Global test set size: {len(X_test_all)}\")\n",
    "\n",
    "### We split the test set to evaluate the accuracy of clf1 and clf2 using the learned clustering\n",
    "\n",
    "c1 = np.where(algo.predict(X_test_all))[0]\n",
    "c2 = [i for i in range(len(X_test_all)) if i not in c1]\n",
    "\n",
    "X_test = X_test_all[c1, :]\n",
    "X_test_h = X_test_all[c2,:]\n",
    "\n",
    "y_test = y_test_all[c1]\n",
    "y_test_h = y_test_all[c2]\n",
    "\n",
    "print(f\"Clf test set size: {len(X_test)}\")\n",
    "print(f\"Human test set size: {len(X_test_h)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage:\n",
    "num_features = X_train.shape[1]  # number of input features\n",
    "dropout = 0.2\n",
    "num_epochs = 200\n",
    "lr = 0.1\n",
    "\n",
    "# define the loss function and optimizer for the l2d_model\n",
    "criterion = nn.BCEWithLogitsLoss()  # use BCEWithLogitsLoss for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha, l2d_model = optimize_alpha([.1,.3,.5,.8,1.], lr, num_features, dropout, num_epochs, X_val, y_val, X_train, X_train_h, y_train, y_train_h, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "test_labels = [y_test, y_test_h]\n",
    "test_features = [X_test, X_test_h]\n",
    "\n",
    "print('Metrics computed using same distributions for train and test set')\n",
    "for i in range(2):\n",
    "    final_predictions, pred_clf, boolean, combined_outputs, decision_outputs = test_time_prediction(l2d_model, test_features[i])\n",
    "    metrics[f\"clf_{i+1}\"] = get_metrics(test_labels[i], pred_clf[:, i])\n",
    "print (json.dumps(metrics, indent=2, default=str))\n",
    "\n",
    "# for the system, we use the global test set\n",
    "print('Metrics computed using the whole test set')\n",
    "final_predictions, pred_clf, boolean, combined_outputs, decision_outputs = test_time_prediction(l2d_model, X_test_all)\n",
    "metrics[f\"clf_{i+1}\"] = get_metrics(y_test_all, pred_clf[:, i])\n",
    "metrics[f\"system\"] = get_metrics(y_test_all, final_predictions)\n",
    "print (json.dumps(metrics, indent=2, default=str))\n",
    "print(f\"Percentage of deferral: {boolean.mean()}\")\n",
    "print(f\"Deferral for positive samples: {boolean[(y_test_all == 1).squeeze()].mean()}\")\n",
    "print(f\"Deferral for negative samples: {boolean[(y_test_all == 0).squeeze()].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Individual metrics\n",
    "\n",
    "for i in range(len(X_test_all)):\n",
    "    print(\n",
    "        f\"y = {y_test_all[i].item()},\", \n",
    "        f\"classifier pred = {combined_outputs[i,0]:.3f},\", \n",
    "        f\"hum model pred = {combined_outputs[i,1]:.3f}\",\n",
    "        \"deferred\" if boolean[i] else \"NOT deferred\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(l2d_model.state_dict(), \"models/l2d_model_demo2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drd2_train_undersampled.iloc[c1].rename(columns = {\"activity\": \"activity_y\"}).to_csv(\"datasets/drd2_train_undersampled_y_ECFP_counts.csv\")\n",
    "drd2_train_undersampled.iloc[c2].rename(columns = {\"activity\": \"activity_h\"}).to_csv(\"datasets/drd2_train_undersampled_h_ECFP_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "L2D",
   "language": "python",
   "name": "l2d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
