{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x117e101b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from helpers.utils import get_metrics, set_matplotlib_params\n",
    "from datasets.moldataset import MolDataHuman\n",
    "from networks.nonlinearnet_aihuman import NonLinearNetDefer, optimization_loop\n",
    "\n",
    "set_matplotlib_params()\n",
    "warnings.filterwarnings('ignore')\n",
    "seed = 12\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (21302, 2052)\n",
      "Train undersampled size: (2420, 2053)\n",
      "Test size: (5404, 2052)\n"
     ]
    }
   ],
   "source": [
    "drd2_train = pd.read_csv(\"datasets/drd2_train_ECFP_counts.csv\")\n",
    "drd2_train_undersampled = pd.read_csv(\"datasets/drd2_train_undersampled_ECFP_counts.csv\")\n",
    "drd2_test = pd.read_csv(\"datasets/drd2_test_ECFP_counts.csv\")\n",
    "d = 2048\n",
    "\n",
    "print(f\"Train size: {drd2_train.shape}\")\n",
    "print(f\"Train undersampled size: {drd2_train_undersampled.shape}\")\n",
    "print(f\"Test size: {drd2_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drd2_train_undersampled[\"activity_y\"] = drd2_train_undersampled.activity.values.tolist()\n",
    "drd2_train_undersampled[\"activity_h\"] = drd2_train_undersampled.activity.values.tolist()\n",
    "\n",
    "drd2_test[\"activity_y\"] = drd2_test.activity.values.tolist()\n",
    "drd2_test[\"activity_h\"] = drd2_test.activity.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = drd2_train_undersampled[[f\"bit{i}\" for i in range(d)]].values\n",
    "train_labels = drd2_train_undersampled[[\"activity_y\", \"activity_h\"]].values\n",
    "\n",
    "test_features = drd2_test[[f\"bit{i}\" for i in range(d)]].values\n",
    "test_labels = drd2_test[[\"activity_y\", \"activity_h\"]].values\n",
    "\n",
    "X_train = torch.tensor(train_features, dtype=torch.float32)\n",
    "y_train = torch.tensor(train_labels, dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor(test_features, dtype=torch.float32)\n",
    "y_test = torch.tensor(test_labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage:\n",
    "num_features = train_features.shape[1]  # number of input features\n",
    "num_epochs = 100\n",
    "lr = 0.1\n",
    "\n",
    "# create an instance of the NonLinearNetDefer\n",
    "l2d_model = NonLinearNetDefer(num_features)\n",
    "\n",
    "# define the loss function and optimizer for the l2d_model\n",
    "criterion = nn.BCEWithLogitsLoss()  # use BCEWithLogitsLoss for binary classification\n",
    "optimizer = optim.SGD(l2d_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n",
    "\n",
    "# binary labels for classifier 1 and classifier 2 (or human model)\n",
    "y = y_train[:,0].unsqueeze(1)\n",
    "h = y_train[:,1].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 2.0738112926483154\n",
      "Epoch [20/100], Loss: 2.004621982574463\n",
      "Epoch [30/100], Loss: 1.9217842817306519\n",
      "Epoch [40/100], Loss: 1.8494293689727783\n",
      "Epoch [50/100], Loss: 1.7975194454193115\n",
      "Epoch [60/100], Loss: 1.7612941265106201\n",
      "Epoch [70/100], Loss: 1.7316551208496094\n",
      "Epoch [80/100], Loss: 1.7079859972000122\n",
      "Epoch [90/100], Loss: 1.6901898384094238\n",
      "Epoch [100/100], Loss: 1.6765260696411133\n"
     ]
    }
   ],
   "source": [
    "optimization_loop(num_epochs, optimizer, l2d_model, X, y, h, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"clf_1\": {\n",
      "    \"Accuracy\": 0.9015544041450777,\n",
      "    \"Precision\": 0.9614195480412367,\n",
      "    \"Recall\": 0.9015544041450777,\n",
      "    \"F1-Score\": 0.9206587738165207\n",
      "  },\n",
      "  \"clf_2\": {\n",
      "    \"Accuracy\": 0.9289415247964471,\n",
      "    \"Precision\": 0.9665384478395359,\n",
      "    \"Recall\": 0.9289415247964471,\n",
      "    \"F1-Score\": 0.9405052962050526\n",
      "  },\n",
      "  \"system\": {\n",
      "    \"Accuracy\": 0.9289415247964471,\n",
      "    \"Precision\": 0.9665384478395359,\n",
      "    \"Recall\": 0.9289415247964471,\n",
      "    \"F1-Score\": 0.9405052962050526\n",
      "  }\n",
      "}\n",
      "Percentage of deferral: 0.8995188474655151\n"
     ]
    }
   ],
   "source": [
    "y = y_test[:,0].unsqueeze(1)\n",
    "h = y_test[:,0].unsqueeze(1) # y = h\n",
    "\n",
    "with torch.no_grad():\n",
    "    l2d_model.eval()\n",
    "    combined_outputs, decision_outputs = l2d_model(X_test)\n",
    "    pred_clf = (combined_outputs > 0.5).float()\n",
    "    metrics = {}\n",
    "    labels = [y, h]\n",
    "    for i in range(2):\n",
    "        metrics[f\"clf_{i+1}\"] = get_metrics(labels[i], pred_clf[:, i])\n",
    "    boolean = (decision_outputs[:, -1] > decision_outputs[:, 0]) * (decision_outputs[:, 1] > decision_outputs[:, 0]) * 1.\n",
    "\n",
    "    final_predictions = (boolean * pred_clf[:, 1]) + (1 - boolean) * pred_clf[:, 0]\n",
    "    metrics[f\"system\"] = get_metrics(labels[0], final_predictions)\n",
    "print (json.dumps(metrics, indent=2, default=str))\n",
    "print(f\"Percentage of deferral: {boolean.mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
