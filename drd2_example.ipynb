{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from helpers.utils import deferral_metrics, get_metrics, set_matplotlib_params\n",
    "from networks.nonlinearnet_aihuman import optimize_alpha, test_time_prediction\n",
    "\n",
    "set_matplotlib_params()\n",
    "warnings.filterwarnings('ignore')\n",
    "seed = 13\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(seed)\n",
    "rng = np.random.default_rng(seed) \n",
    "torch.set_default_dtype(torch.double)\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global train set size: 2420\n",
      "Clf train set size: 1017\n",
      "Human train set size: 1403\n",
      "\n",
      "Validation set size: 186\n",
      "\n",
      "Global test set size: 744\n",
      "Clf test set size: 261\n",
      "Human test set size: 483\n"
     ]
    }
   ],
   "source": [
    "### From the undersampled training set, create two training sets: one for clf, one for human, based on K-means (K=2)\n",
    "\n",
    "drd2_train_undersampled = pd.read_csv(\"datasets/drd2_train_undersampled_ECFP_counts.csv\")\n",
    "d = 2048\n",
    "\n",
    "X_train_all = torch.tensor(drd2_train_undersampled[[f\"bit{i}\" for i in range(d)]].values, dtype=torch.double)\n",
    "y_train_all = torch.tensor(drd2_train_undersampled.activity.values, dtype=torch.double)\n",
    "\n",
    "algo = KMeans(n_clusters=2, random_state=seed, n_init=20, max_iter=5000, init=\"k-means++\")\n",
    "algo.fit(X_train_all)\n",
    "c1_train = np.where(algo.labels_)[0]\n",
    "c2_train = [i for i in range(len(X_train_all)) if i not in c1_train]\n",
    "\n",
    "X_train = X_train_all[c1_train, :]\n",
    "X_train_h = X_train_all[c2_train,:]\n",
    "\n",
    "y_train = y_train_all[c1_train].unsqueeze(1)\n",
    "y_train_h = y_train_all[c2_train].unsqueeze(1)\n",
    "\n",
    "### Test set, making it balanced\n",
    "\n",
    "drd2_test = pd.read_csv(\"datasets/drd2_test_ECFP_counts.csv\")\n",
    "X_test_all = torch.tensor(drd2_test[[f\"bit{i}\" for i in range(d)]].values, dtype=torch.double)\n",
    "y_test_all = torch.tensor(drd2_test.activity.values, dtype=torch.double)\n",
    "\n",
    "idx_active = torch.where(y_test_all)[0].numpy()\n",
    "idx_inactive = [i for i in range(len(y_test_all)) if i not in idx_active]\n",
    "idx_inactive = rng.choice(range(len(y_test_all)), 600, replace=False)\n",
    "idx = np.r_[idx_active,idx_inactive]\n",
    "y_test_all = y_test_all[idx]\n",
    "X_test_all = X_test_all[idx]\n",
    "\n",
    "### Validation set as a fraction of the test set\n",
    "\n",
    "frac = .2\n",
    "ntest = len(X_test_all)\n",
    "nval = int(ntest * frac)\n",
    "idx = rng.choice(range(ntest), nval, replace=False)\n",
    "X_val = X_test_all[idx]\n",
    "y_val = y_test_all[idx].unsqueeze(1)\n",
    "\n",
    "notidx = [i for i in range(ntest) if i not in idx]\n",
    "X_test_all = X_test_all[notidx]\n",
    "y_test_all = y_test_all[notidx].unsqueeze(1)\n",
    "print(f\"Global train set size: {len(X_train_all)}\")\n",
    "print(f\"Clf train set size: {len(X_train)}\")\n",
    "print(f\"Human train set size: {len(X_train_h)}\\n\")\n",
    "print(f\"Validation set size: {len(X_val)}\\n\")\n",
    "print(f\"Global test set size: {len(X_test_all)}\")\n",
    "\n",
    "### We split the test set to evaluate the accuracy of clf1 and clf2 using the learned clustering\n",
    "\n",
    "c1 = np.where(algo.predict(X_test_all))[0]\n",
    "c2 = [i for i in range(len(X_test_all)) if i not in c1]\n",
    "\n",
    "X_test = X_test_all[c1, :]\n",
    "X_test_h = X_test_all[c2,:]\n",
    "\n",
    "y_test = y_test_all[c1]\n",
    "y_test_h = y_test_all[c2]\n",
    "\n",
    "print(f\"Clf test set size: {len(X_test)}\")\n",
    "print(f\"Human test set size: {len(X_test_h)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage:\n",
    "num_features = X_train.shape[1]  # number of input features\n",
    "dropout = 0.2\n",
    "num_epochs = 200\n",
    "lr = 0.1\n",
    "\n",
    "# define the loss function and optimizer for the l2d_model\n",
    "criterion = nn.BCEWithLogitsLoss()  # use BCEWithLogitsLoss for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 0.7522146072250827\n",
      "Epoch [20/200], Loss: 0.731348359372798\n",
      "Epoch [30/200], Loss: 0.7163762455265081\n",
      "Epoch [40/200], Loss: 0.7049626936135959\n",
      "Epoch [50/200], Loss: 0.6938851463459835\n"
     ]
    }
   ],
   "source": [
    "best_alpha, l2d_model = optimize_alpha([.1,.3,.5,.8,1.], lr, num_features, dropout, num_epochs, X_val, y_val, X_train, X_train_h, y_train, y_train_h, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "test_labels = [y_test, y_test_h]\n",
    "test_features = [X_test, X_test_h]\n",
    "\n",
    "print('Metrics computed using same distributions for train and test set')\n",
    "for i in range(2):\n",
    "    final_predictions, pred_clf, boolean, combined_outputs, decision_outputs = test_time_prediction(l2d_model, test_features[i])\n",
    "    metrics[f\"clf_{i+1}\"] = get_metrics(test_labels[i], pred_clf[:, i])\n",
    "print (json.dumps(metrics, indent=2, default=str))\n",
    "metrics = {}\n",
    "# for the system, we use the global test set\n",
    "print('Metrics computed using the whole test set')\n",
    "final_predictions, pred_clf, boolean, combined_outputs, decision_outputs = test_time_prediction(l2d_model, X_test_all)\n",
    "for i in range(2):\n",
    "    metrics[f\"clf_{i+1}\"] = get_metrics(y_test_all, pred_clf[:, i])\n",
    "metrics[f\"system\"] = get_metrics(y_test_all, final_predictions)\n",
    "print (json.dumps(metrics, indent=2, default=str))\n",
    "print(f\"Percentage of deferral: {boolean.mean()}\")\n",
    "for i in range(2):\n",
    "     print(f'--- For label {i} ---')\n",
    "     ndefer, ndefersuccess, ndeferuseful = deferral_metrics(y_test_all.squeeze(), pred_clf, boolean, i)\n",
    "     print(f\"Deferral: {ndefer} / {(y_test_all == i).sum()}\")\n",
    "     print(f\"Successful deferrals: {ndefersuccess} / {ndefer}\")\n",
    "     print(f\"Useful deferrals: {ndeferuseful} / {ndefersuccess}\\n\")\n",
    "# print(f\"of which {} were successful defers\")\n",
    "\n",
    "# print(f\"Deferral for negative samples: {boolean[(y_test_all == 0).squeeze()].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Individual metrics\n",
    "\n",
    "for i in range(len(X_test_all)):\n",
    "    print(\n",
    "        f\"y = {y_test_all[i].item()},\", \n",
    "        f\"classifier pred = {combined_outputs[i,0]:.3f},\", \n",
    "        f\"hum model pred = {combined_outputs[i,1]:.3f}\",\n",
    "        \"deferred\" if boolean[i] else \"NOT deferred\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(l2d_model.state_dict(), \"models/l2d_model_demo2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drd2_train_undersampled.iloc[c1].rename(columns = {\"activity\": \"activity_y\"}).to_csv(\"datasets/drd2_train_undersampled_y_ECFP_counts.csv\")\n",
    "drd2_train_undersampled.iloc[c2].rename(columns = {\"activity\": \"activity_h\"}).to_csv(\"datasets/drd2_train_undersampled_h_ECFP_counts.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "L2D",
   "language": "python",
   "name": "l2d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
